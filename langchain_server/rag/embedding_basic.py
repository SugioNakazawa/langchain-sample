"""
LangChain Embedding åŸºæœ¬ã‚µãƒ³ãƒ—ãƒ«

ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã¯ã€ä»¥ä¸‹ã®åŸºæœ¬çš„ãªembeddingæ“ä½œã‚’å®Ÿæ¼”ã—ã¾ã™ï¼š
1. ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–
2. é¡ä¼¼åº¦æ¤œç´¢
3. ç°¡å˜ãªã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢
"""

import asyncio
from typing import List
import numpy as np
from langchain_community.embeddings import OllamaEmbeddings
from langchain_core.documents import Document

# ===== è¨­å®š =====
def get_embeddings():
    """Embedding ãƒ¢ãƒ‡ãƒ«ã‚’å–å¾—"""
    return OllamaEmbeddings(
        base_url="http://localhost:11434",
        model="mxbai-embed-large"  # Ollamaã®è»½é‡embedgingãƒ¢ãƒ‡ãƒ«
    )

# ===== 1. åŸºæœ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ– =====
async def basic_embedding_example():
    """åŸºæœ¬çš„ãªembeddingç”Ÿæˆã®ä¾‹"""
    print("\n" + "="*70)
    print("1ï¸âƒ£  åŸºæœ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–")
    print("="*70)
    
    embeddings = get_embeddings()
    
    # å˜ä¸€ãƒ†ã‚­ã‚¹ãƒˆã®embedding
    text = "äººå·¥çŸ¥èƒ½ã¨æ©Ÿæ¢°å­¦ç¿’ã¯ç¾ä»£æŠ€è¡“ã®é‡è¦ãªåˆ†é‡ã§ã™ã€‚"
    
    print(f"ğŸ“ å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆ: {text}")
    
    # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    vector = await embeddings.aembed_query(text)
    
    print(f"ğŸ“Š ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒæ•°: {len(vector)}")
    print(f"ğŸ“ˆ ãƒ™ã‚¯ãƒˆãƒ«ã®æœ€åˆã®10è¦ç´ : {vector[:10]}")
    print(f"âœ… ãƒ™ã‚¯ãƒˆãƒ«åŒ–å®Œäº†")
    
    return vector

# ===== 2. è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒƒãƒå‡¦ç† =====
async def batch_embedding_example():
    """è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆã®embeddingç”Ÿæˆ"""
    print("\n" + "="*70)
    print("2ï¸âƒ£  è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒƒãƒembedding")
    print("="*70)
    
    embeddings = get_embeddings()
    
    # è¤‡æ•°ã®ãƒ†ã‚­ã‚¹ãƒˆ
    texts = [
        "Pythonã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã™ã€‚",
        "æ©Ÿæ¢°å­¦ç¿’ã«ã¯ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™ã€‚",
        "æ·±å±¤å­¦ç¿’ã¯ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚",
        "è‡ªç„¶è¨€èªå‡¦ç†ã¯ãƒ†ã‚­ã‚¹ãƒˆã‚’æ‰±ã„ã¾ã™ã€‚"
    ]
    
    print("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚¹ãƒˆ:")
    for i, text in enumerate(texts, 1):
        print(f"  {i}. {text}")
    
    # ãƒãƒƒãƒã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    vectors = await embeddings.aembed_documents(texts)
    
    print(f"\nğŸ“Š ç”Ÿæˆã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«æ•°: {len(vectors)}")
    print(f"ğŸ“ å„ãƒ™ã‚¯ãƒˆãƒ«ã®æ¬¡å…ƒ: {len(vectors[0])}")
    print("âœ… ãƒãƒƒãƒå‡¦ç†å®Œäº†")
    
    return texts, vectors

# ===== 3. ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦è¨ˆç®— =====
def cosine_similarity(vec1: List[float], vec2: List[float]) -> float:
    """2ã¤ã®ãƒ™ã‚¯ãƒˆãƒ«é–“ã®ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
    vec1_np = np.array(vec1)
    vec2_np = np.array(vec2)
    
    dot_product = np.dot(vec1_np, vec2_np)
    norm1 = np.linalg.norm(vec1_np)
    norm2 = np.linalg.norm(vec2_np)
    
    return dot_product / (norm1 * norm2)

async def similarity_search_example():
    """é¡ä¼¼åº¦æ¤œç´¢ã®ä¾‹"""
    print("\n" + "="*70)
    print("3ï¸âƒ£  é¡ä¼¼åº¦æ¤œç´¢")
    print("="*70)
    
    embeddings = get_embeddings()
    
    # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
    documents = [
        "çŒ«ã¯å¯æ„›ã„ãƒšãƒƒãƒˆã§ã™ã€‚",
        "çŠ¬ã¯å¿ å®Ÿãªå‹é”ã§ã™ã€‚",
        "Pythonã¯ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã§ã™ã€‚",
        "æ©Ÿæ¢°å­¦ç¿’ã¯AIã®ä¸€åˆ†é‡ã§ã™ã€‚",
        "é³¥ã¯ç©ºã‚’é£›ã³ã¾ã™ã€‚",
        "é­šã¯æ°´ä¸­ã§ç”Ÿæ´»ã—ã¾ã™ã€‚",
        "è‡ªç„¶è¨€èªå‡¦ç†ã¯ãƒ†ã‚­ã‚¹ãƒˆåˆ†æã«ä½¿ã‚ã‚Œã¾ã™ã€‚",
        "æ·±å±¤å­¦ç¿’ã¯ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’æ´»ç”¨ã—ã¾ã™ã€‚"
    ]
    
    # ã‚¯ã‚¨ãƒª
    query = "ãƒšãƒƒãƒˆã«ã¤ã„ã¦æ•™ãˆã¦"
    
    print(f"ğŸ” ã‚¯ã‚¨ãƒª: {query}\n")
    print("ğŸ“š ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³:")
    for i, doc in enumerate(documents, 1):
        print(f"  {i}. {doc}")
    
    # ã‚¯ã‚¨ãƒªã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    query_vector = await embeddings.aembed_query(query)
    doc_vectors = await embeddings.aembed_documents(documents)
    
    # é¡ä¼¼åº¦ã‚’è¨ˆç®—
    similarities = []
    for i, doc_vector in enumerate(doc_vectors):
        similarity = cosine_similarity(query_vector, doc_vector)
        similarities.append((i, documents[i], similarity))
    
    # é¡ä¼¼åº¦ã§ã‚½ãƒ¼ãƒˆ
    similarities.sort(key=lambda x: x[2], reverse=True)
    
    print("\nğŸ¯ é¡ä¼¼åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆä¸Šä½5ä»¶ï¼‰:")
    for rank, (idx, doc, score) in enumerate(similarities[:5], 1):
        print(f"  {rank}ä½ (é¡ä¼¼åº¦: {score:.4f}): {doc}")
    
    return similarities

# ===== 4. ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢ =====
async def semantic_search_example():
    """æ„å‘³çš„ã«é¡ä¼¼ã—ãŸæ–‡ç« ã‚’æ¤œç´¢"""
    print("\n" + "="*70)
    print("4ï¸âƒ£  ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢")
    print("="*70)
    
    embeddings = get_embeddings()
    
    # æŠ€è¡“è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
    articles = [
        "Pythonã§å§‹ã‚ã‚‹æ©Ÿæ¢°å­¦ç¿’å…¥é–€",
        "æ·±å±¤å­¦ç¿’ã®åŸºç¤ï¼šãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚’ç†è§£ã™ã‚‹",
        "è‡ªç„¶è¨€èªå‡¦ç†ã®æœ€æ–°æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰",
        "ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã®ãŸã‚ã®Pandasæ´»ç”¨è¡“",
        "ã‚¯ãƒ©ã‚¦ãƒ‰ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã®åŸºæœ¬æ¦‚å¿µ",
        "Dockerã‚³ãƒ³ãƒ†ãƒŠã§é–‹ç™ºç’°å¢ƒã‚’æ§‹ç¯‰ã™ã‚‹æ–¹æ³•",
        "RESTful APIè¨­è¨ˆã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹",
        "æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæˆ¦ç•¥",
        "Transformerã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¨BERTã®è§£èª¬",
        "æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿åˆ†æã¨LSTMãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯"
    ]
    
    queries = [
        "AIã«ã¤ã„ã¦å­¦ã³ãŸã„",
        "Pythonã®ä½¿ã„æ–¹ã‚’çŸ¥ã‚ŠãŸã„",
        "ã‚¤ãƒ³ãƒ•ãƒ©ã®æ§‹ç¯‰æ–¹æ³•"
    ]
    
    print("ğŸ“š è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³:")
    for i, article in enumerate(articles, 1):
        print(f"  {i:2d}. {article}")
    
    # è¨˜äº‹ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    article_vectors = await embeddings.aembed_documents(articles)
    
    for query in queries:
        print(f"\nğŸ” ã‚¯ã‚¨ãƒª: ã€Œ{query}ã€")
        
        # ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
        query_vector = await embeddings.aembed_query(query)
        
        # é¡ä¼¼åº¦è¨ˆç®—
        results = []
        for i, article_vector in enumerate(article_vectors):
            similarity = cosine_similarity(query_vector, article_vector)
            results.append((articles[i], similarity))
        
        # ã‚½ãƒ¼ãƒˆã—ã¦ä¸Šä½3ä»¶è¡¨ç¤º
        results.sort(key=lambda x: x[1], reverse=True)
        
        print("  ğŸ“– é–¢é€£è¨˜äº‹ï¼ˆä¸Šä½3ä»¶ï¼‰:")
        for rank, (article, score) in enumerate(results[:3], 1):
            print(f"    {rank}. {article} (é¡ä¼¼åº¦: {score:.4f})")

# ===== 5. å¤šè¨€èªembedding =====
async def multilingual_embedding_example():
    """å¤šè¨€èªãƒ†ã‚­ã‚¹ãƒˆã®embedding"""
    print("\n" + "="*70)
    print("5ï¸âƒ£  å¤šè¨€èªembedding")
    print("="*70)
    
    embeddings = get_embeddings()
    
    # åŒã˜æ„å‘³ã®ç•°ãªã‚‹è¨€èªã®ãƒ†ã‚­ã‚¹ãƒˆ
    texts = {
        "æ—¥æœ¬èª": "ã“ã‚“ã«ã¡ã¯ã€ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã­ã€‚",
        "è‹±èª": "Hello, it's a nice day today.",
        "é–¢é€£": "å¤©æ°—ãŒè‰¯ãã¦æ°—æŒã¡ã„ã„ã§ã™ã€‚",
        "éé–¢é€£": "ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã¯æ¥½ã—ã„ã§ã™ã€‚"
    }
    
    print("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆã‚µãƒ³ãƒ—ãƒ«:")
    for lang, text in texts.items():
        print(f"  {lang}: {text}")
    
    # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
    vectors = {}
    for lang, text in texts.items():
        vectors[lang] = await embeddings.aembed_query(text)
    
    # é¡ä¼¼åº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹
    print("\nğŸ“Š é¡ä¼¼åº¦ãƒãƒˆãƒªãƒƒã‚¯ã‚¹:")
    print(f"{'':12}", end="")
    for lang in texts.keys():
        print(f"{lang:12}", end="")
    print()
    
    for lang1 in texts.keys():
        print(f"{lang1:12}", end="")
        for lang2 in texts.keys():
            similarity = cosine_similarity(vectors[lang1], vectors[lang2])
            print(f"{similarity:12.4f}", end="")
        print()
    
    print("\nğŸ’¡ è¦³å¯Ÿ:")
    print("  - æ—¥æœ¬èªã¨è‹±èªï¼ˆåŒã˜æ„å‘³ï¼‰ã®é¡ä¼¼åº¦ãŒé«˜ã„")
    print("  - é–¢é€£ãƒ†ã‚­ã‚¹ãƒˆã‚‚æ¯”è¼ƒçš„é«˜ã„é¡ä¼¼åº¦")
    print("  - éé–¢é€£ãƒ†ã‚­ã‚¹ãƒˆã¯é¡ä¼¼åº¦ãŒä½ã„")

# ===== ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ =====
async def main():
    """å…¨ã¦ã®ã‚µãƒ³ãƒ—ãƒ«ã‚’å®Ÿè¡Œ"""
    print("\n" + "ğŸŒŸ"*35)
    print("LangChain Embedding åŸºæœ¬ã‚µãƒ³ãƒ—ãƒ«é›†")
    print("ğŸŒŸ"*35)
    
    examples = [
        ("åŸºæœ¬çš„ãªãƒ†ã‚­ã‚¹ãƒˆã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–", basic_embedding_example),
        ("è¤‡æ•°ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒƒãƒembedding", batch_embedding_example),
        ("é¡ä¼¼åº¦æ¤œç´¢", similarity_search_example),
        ("ã‚»ãƒãƒ³ãƒ†ã‚£ãƒƒã‚¯æ¤œç´¢", semantic_search_example),
        ("å¤šè¨€èªembedding", multilingual_embedding_example),
    ]
    
    print("\nå®Ÿè¡Œã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„:")
    for i, (name, _) in enumerate(examples, 1):
        print(f"{i}. {name}")
    print("0. å…¨ã¦å®Ÿè¡Œ")
    
    try:
        choice = input("\nç•ªå·ã‚’å…¥åŠ› (0-5): ").strip()
        
        if choice == "0":
            for name, func in examples:
                await func()
        elif choice.isdigit() and 1 <= int(choice) <= len(examples):
            _, func = examples[int(choice) - 1]
            await func()
        else:
            print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
            return
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸  å®Ÿè¡ŒãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "ğŸ‰"*35)
    print("ã‚µãƒ³ãƒ—ãƒ«å®Ÿè¡Œå®Œäº†ï¼")
    print("ğŸ‰"*35 + "\n")

if __name__ == "__main__":
    asyncio.run(main())
