"""
LangChain ãƒã‚§ãƒ¼ãƒ³ å®Ÿç”¨ä¾‹é›†

å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚’æƒ³å®šã—ãŸãƒã‚§ãƒ¼ãƒ³ã®çµ„ã¿åˆã‚ã›ãƒ‘ã‚¿ãƒ¼ãƒ³
"""

import asyncio
from typing import Dict, List
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel

def get_llm(streaming: bool = False):
    return ChatOpenAI(
        openai_api_base="http://localhost:11434/v1",
        streaming=streaming,
        temperature=0.7,
        openai_api_key="EMPTY",
        model="qwen3:8b"
    )

# ===== ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ 1: ãƒ–ãƒ­ã‚°è¨˜äº‹è‡ªå‹•ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  =====
async def blog_generation_pipeline():
    """ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹å®Œå…¨ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""
    print("\n" + "="*70)
    print("ğŸ“ ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹1: ãƒ–ãƒ­ã‚°è¨˜äº‹è‡ªå‹•ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ")
    print("="*70)
    
    # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒˆãƒ”ãƒƒã‚¯åˆ†æ
    topic_analysis_prompt = ChatPromptTemplate.from_template(
        """ä»¥ä¸‹ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‹ã‚‰ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆèª­è€…ã¨è¨˜äº‹ã®ç›®çš„ã‚’åˆ†æã—ã¦ãã ã•ã„ï¼š
        
ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keywords}

ä»¥ä¸‹ã®å½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š
- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆèª­è€…: 
- è¨˜äº‹ã®ç›®çš„: 
- ãƒˆãƒ¼ãƒ³: """
    )
    
    # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆï¼ˆ3ã¤ï¼‰
    title_generation_prompt = ChatPromptTemplate.from_template(
        """ä»¥ä¸‹ã®æƒ…å ±ã«åŸºã¥ã„ã¦ã€é­…åŠ›çš„ãªãƒ–ãƒ­ã‚°ã‚¿ã‚¤ãƒˆãƒ«ã‚’3ã¤ææ¡ˆã—ã¦ãã ã•ã„ï¼š

{analysis}

ã‚¿ã‚¤ãƒˆãƒ«å€™è£œã‚’ç•ªå·ä»˜ããƒªã‚¹ãƒˆã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"""
    )
    
    # ã‚¹ãƒ†ãƒƒãƒ—3: æ§‹æˆä½œæˆ
    outline_prompt = ChatPromptTemplate.from_template(
        """ä»¥ä¸‹ã®ã‚¿ã‚¤ãƒˆãƒ«ã«åŸºã¥ã„ã¦ã€ãƒ–ãƒ­ã‚°è¨˜äº‹ã®æ§‹æˆï¼ˆè¦‹å‡ºã—ï¼‰ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼š

{title}

ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ï¼š
1. å°å…¥
2. [ãƒ¡ã‚¤ãƒ³ãƒã‚¤ãƒ³ãƒˆ1]
3. [ãƒ¡ã‚¤ãƒ³ãƒã‚¤ãƒ³ãƒˆ2]
4. [ãƒ¡ã‚¤ãƒ³ãƒã‚¤ãƒ³ãƒˆ3]
5. ã¾ã¨ã‚"""
    )
    
    # ã‚¹ãƒ†ãƒƒãƒ—4: å„ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®æœ¬æ–‡ç”Ÿæˆï¼ˆä¸¦åˆ—å®Ÿè¡Œï¼‰
    section_prompt = ChatPromptTemplate.from_template(
        """ä»¥ä¸‹ã®è¦‹å‡ºã—ã«ã¤ã„ã¦ã€150æ–‡å­—ç¨‹åº¦ã§å†…å®¹ã‚’æ›¸ã„ã¦ãã ã•ã„ï¼š

è¦‹å‡ºã—: {heading}
å…¨ä½“ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context}"""
    )
    
    # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰
    analysis_chain = topic_analysis_prompt | get_llm() | StrOutputParser()
    title_chain = title_generation_prompt | get_llm() | StrOutputParser()
    outline_chain = outline_prompt | get_llm() | StrOutputParser()
    
    # å®Ÿè¡Œ
    keywords = "AIã€æ©Ÿæ¢°å­¦ç¿’ã€Pythonã€åˆå¿ƒè€…"
    
    print(f"ğŸ” å…¥åŠ›ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keywords}\n")
    
    # åˆ†æå®Ÿè¡Œ
    analysis = await analysis_chain.ainvoke({"keywords": keywords})
    print(f"ğŸ“Š ãƒˆãƒ”ãƒƒã‚¯åˆ†æ:\n{analysis}\n")
    
    # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆ
    titles = await title_chain.ainvoke({"analysis": analysis})
    print(f"ğŸ“Œ ã‚¿ã‚¤ãƒˆãƒ«å€™è£œ:\n{titles}\n")
    
    # æœ€åˆã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½¿ç”¨
    selected_title = titles.split('\n')[0].strip()
    print(f"âœ… é¸æŠã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«: {selected_title}\n")
    
    # æ§‹æˆä½œæˆ
    outline = await outline_chain.ainvoke({"title": selected_title})
    print(f"ğŸ“‹ è¨˜äº‹æ§‹æˆ:\n{outline}\n")
    
    return {
        "analysis": analysis,
        "title": selected_title,
        "outline": outline
    }

# ===== ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ 2: ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆãƒœãƒƒãƒˆ =====
async def customer_support_bot():
    """å•ã„åˆã‚ã›ã‚’åˆ†é¡ã—ã¦é©åˆ‡ã«å¿œç­”"""
    print("\n" + "="*70)
    print("ğŸ§ ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹2: ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆãƒœãƒƒãƒˆ")
    print("="*70)
    
    # åˆ†é¡ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    classify_prompt = ChatPromptTemplate.from_template(
        """ä»¥ä¸‹ã®å•ã„åˆã‚ã›ã‚’åˆ†é¡ã—ã¦ãã ã•ã„ã€‚

å•ã„åˆã‚ã›: {query}

ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã§åˆ†é¡ã—ã¦ãã ã•ã„ï¼š
- technical: æŠ€è¡“çš„ãªå•é¡Œ
- billing: è«‹æ±‚ãƒ»æ”¯æ‰•ã„é–¢é€£
- general: ä¸€èˆ¬çš„ãªè³ªå•

åˆ†é¡çµæœã®ã¿ã‚’å›ç­”ã—ã¦ãã ã•ã„ã€‚"""
    )
    
    # å¿œç­”ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥ï¼‰
    technical_prompt = ChatPromptTemplate.from_template(
        """æŠ€è¡“ã‚µãƒãƒ¼ãƒˆæ‹…å½“ã¨ã—ã¦ã€ä»¥ä¸‹ã®å•é¡Œã«å¯¾ã™ã‚‹è§£æ±ºç­–ã‚’ææ¡ˆã—ã¦ãã ã•ã„ï¼š

å•é¡Œ: {query}

æ‰‹é †ã‚’æ˜ç¢ºã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"""
    )
    
    billing_prompt = ChatPromptTemplate.from_template(
        """è«‹æ±‚ã‚µãƒãƒ¼ãƒˆæ‹…å½“ã¨ã—ã¦ã€ä»¥ä¸‹ã®å•ã„åˆã‚ã›ã«ä¸å¯§ã«å›ç­”ã—ã¦ãã ã•ã„ï¼š

å•ã„åˆã‚ã›: {query}

å¿…è¦ãªæƒ…å ±ã‚„æ‰‹ç¶šãã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"""
    )
    
    general_prompt = ChatPromptTemplate.from_template(
        """ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆæ‹…å½“ã¨ã—ã¦ã€ä»¥ä¸‹ã®è³ªå•ã«è¦ªåˆ‡ã«å›ç­”ã—ã¦ãã ã•ã„ï¼š

è³ªå•: {query}

ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"""
    )
    
    # ãƒ«ãƒ¼ã‚¿ãƒ¼é–¢æ•°
    def route_query(inputs: Dict):
        category = inputs["category"].strip().lower()
        query = inputs["query"]
        
        if "technical" in category:
            return technical_prompt | get_llm() | StrOutputParser()
        elif "billing" in category:
            return billing_prompt | get_llm() | StrOutputParser()
        else:
            return general_prompt | get_llm() | StrOutputParser()
    
    # ãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰
    chain = (
        RunnableParallel(
            query=RunnablePassthrough(),
            category=(classify_prompt | get_llm() | StrOutputParser())
        )
        | RunnableLambda(route_query)
    )
    
    # ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    queries = [
        "ãƒ­ã‚°ã‚¤ãƒ³ã§ããªããªã‚Šã¾ã—ãŸã€‚ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã‚’ãƒªã‚»ãƒƒãƒˆã™ã‚‹æ–¹æ³•ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚",
        "ä»Šæœˆã®è«‹æ±‚é¡ãŒäºˆæƒ³ã‚ˆã‚Šé«˜ã„ã®ã§ã™ãŒã€æ˜ç´°ã‚’ç¢ºèªã—ãŸã„ã§ã™ã€‚",
        "å–¶æ¥­æ™‚é–“ã¯ä½•æ™‚ã‹ã‚‰ä½•æ™‚ã¾ã§ã§ã™ã‹ï¼Ÿ"
    ]
    
    for query in queries:
        print(f"\nâ“ å•ã„åˆã‚ã›: {query}")
        response = await chain.ainvoke(query)
        print(f"ğŸ’¬ å›ç­”: {response}")
        print("-" * 70)

# ===== ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ 3: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªãƒã‚§ãƒƒã‚«ãƒ¼ =====
async def content_quality_checker():
    """ãƒ†ã‚­ã‚¹ãƒˆã®å“è³ªã‚’å¤šè§’çš„ã«è©•ä¾¡"""
    print("\n" + "="*70)
    print("ğŸ” ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹3: ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªãƒã‚§ãƒƒã‚«ãƒ¼")
    print("="*70)
    
    # å„è©•ä¾¡è»¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    readability_prompt = ChatPromptTemplate.from_template(
        """ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã®èª­ã¿ã‚„ã™ã•ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ï¼ˆ1-10ç‚¹ï¼‰ï¼š

{text}

è©•ä¾¡ç‚¹ã¨ç†ç”±ã‚’ç°¡æ½”ã«èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"""
    )
    
    grammar_prompt = ChatPromptTemplate.from_template(
        """ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã®æ–‡æ³•ãƒ»è¡¨ç¾ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¦ãã ã•ã„ï¼š

{text}

å•é¡Œç‚¹ãŒã‚ã‚Œã°æŒ‡æ‘˜ã—ã€æ”¹å–„æ¡ˆã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚ãªã‘ã‚Œã°ã€Œå•é¡Œãªã—ã€ã¨å›ç­”ã—ã¦ãã ã•ã„ã€‚"""
    )
    
    tone_prompt = ChatPromptTemplate.from_template(
        """ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ãƒ³ï¼ˆæ–‡ä½“ï¼‰ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ï¼š

{text}

ãƒ•ã‚©ãƒ¼ãƒãƒ«åº¦ã€è¦ªã—ã¿ã‚„ã™ã•ã€ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«åº¦ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚"""
    )
    
    seo_prompt = ChatPromptTemplate.from_template(
        """ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã®SEOè¦³ç‚¹ã§ã®è©•ä¾¡ã‚’ã—ã¦ãã ã•ã„ï¼š

{text}

ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®é©åˆ‡ã•ã€æ§‹é€ ã€æ”¹å–„ææ¡ˆã‚’å«ã‚ã¦ãã ã•ã„ã€‚"""
    )
    
    # ä¸¦åˆ—è©•ä¾¡ãƒã‚§ãƒ¼ãƒ³
    quality_chain = RunnableParallel(
        readability=(readability_prompt | get_llm() | StrOutputParser()),
        grammar=(grammar_prompt | get_llm() | StrOutputParser()),
        tone=(tone_prompt | get_llm() | StrOutputParser()),
        seo=(seo_prompt | get_llm() | StrOutputParser())
    )
    
    # ãƒ†ã‚¹ãƒˆãƒ†ã‚­ã‚¹ãƒˆ
    text = """
    AIã¨æ©Ÿæ¢°å­¦ç¿’ã¯ç¾ä»£ã®ãƒ“ã‚¸ãƒã‚¹ã«é©å‘½ã‚’ã‚‚ãŸã‚‰ã—ã¦ã„ã¾ã™ã€‚
    ä¼æ¥­ã¯ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ã¦æ„æ€æ±ºå®šã‚’æœ€é©åŒ–ã—ã€
    é¡§å®¢ä½“é¨“ã‚’å‘ä¸Šã•ã›ã‚‹ã“ã¨ãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸã€‚
    Pythonè¨€èªã‚’ä½¿ãˆã°ã€èª°ã§ã‚‚ç°¡å˜ã«AIãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã§ãã¾ã™ã€‚
    """
    
    print(f"ğŸ“„ è©•ä¾¡å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ:\n{text.strip()}\n")
    
    results = await quality_chain.ainvoke({"text": text})
    
    print("ğŸ“Š è©•ä¾¡çµæœ:\n")
    print(f"ã€èª­ã¿ã‚„ã™ã•ã€‘\n{results['readability']}\n")
    print(f"ã€æ–‡æ³•ãƒ»è¡¨ç¾ã€‘\n{results['grammar']}\n")
    print(f"ã€ãƒˆãƒ¼ãƒ³ã€‘\n{results['tone']}\n")
    print(f"ã€SEOã€‘\n{results['seo']}\n")

# ===== ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ 4: ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ =====
async def data_analysis_report():
    """ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
    print("\n" + "="*70)
    print("ğŸ“ˆ ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹4: ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
    print("="*70)
    
    # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
    def preprocess_data(inputs: Dict) -> Dict:
        """ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’è¨ˆç®—"""
        data = inputs["data"]
        
        # ç°¡å˜ãªçµ±è¨ˆè¨ˆç®—
        total = sum(data)
        average = total / len(data)
        max_val = max(data)
        min_val = min(data)
        
        return {
            "raw_data": data,
            "total": total,
            "average": average,
            "max": max_val,
            "min": min_val,
            "count": len(data)
        }
    
    # åˆ†æãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆä¸¦åˆ—å®Ÿè¡Œï¼‰
    trend_prompt = ChatPromptTemplate.from_template(
        """ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’åˆ†æã—ã¦ãã ã•ã„ï¼š

åˆè¨ˆ: {total}
å¹³å‡: {average}
æœ€å¤§: {max}
æœ€å°: {min}
ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°: {count}

ãƒˆãƒ¬ãƒ³ãƒ‰ã¨å‚¾å‘ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚"""
    )
    
    insight_prompt = ChatPromptTemplate.from_template(
        """ä»¥ä¸‹ã®çµ±è¨ˆæƒ…å ±ã‹ã‚‰ã€ãƒ“ã‚¸ãƒã‚¹ä¸Šã®æ´å¯Ÿã‚’æä¾›ã—ã¦ãã ã•ã„ï¼š

åˆè¨ˆ: {total}
å¹³å‡: {average}
æœ€å¤§: {max}
æœ€å°: {min}

ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã‚’å«ã‚ã¦ãã ã•ã„ã€‚"""
    )
    
    summary_prompt = ChatPromptTemplate.from_template(
        """ä»¥ä¸‹ã®åˆ†æçµæœã‚’ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼ã¨ã—ã¦ã¾ã¨ã‚ã¦ãã ã•ã„ï¼š

ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ:
{trend}

ãƒ“ã‚¸ãƒã‚¹æ´å¯Ÿ:
{insight}

3è¡Œç¨‹åº¦ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚"""
    )
    
    # ãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰
    chain = (
        RunnableLambda(preprocess_data)
        | RunnableParallel(
            stats=RunnablePassthrough(),
            trend=(trend_prompt | get_llm() | StrOutputParser()),
            insight=(insight_prompt | get_llm() | StrOutputParser())
        )
        | RunnableParallel(
            trend=lambda x: x["trend"],
            insight=lambda x: x["insight"],
            summary=(
                RunnableLambda(lambda x: {"trend": x["trend"], "insight": x["insight"]})
                | summary_prompt
                | get_llm()
                | StrOutputParser()
            )
        )
    )
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆæœˆæ¬¡å£²ä¸Šï¼‰
    sales_data = [120, 135, 150, 145, 160, 175, 180, 195, 210, 205, 225, 240]
    
    print(f"ğŸ“Š å£²ä¸Šãƒ‡ãƒ¼ã‚¿ï¼ˆæœˆæ¬¡ï¼‰: {sales_data}\n")
    
    result = await chain.ainvoke({"data": sales_data})
    
    print(f"ğŸ“ˆ ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ:\n{result['trend']}\n")
    print(f"ğŸ’¡ ãƒ“ã‚¸ãƒã‚¹æ´å¯Ÿ:\n{result['insight']}\n")
    print(f"ğŸ“‹ ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ã‚µãƒãƒªãƒ¼:\n{result['summary']}\n")

# ===== ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ =====
async def main():
    """å…¨ã¦ã®å®Ÿç”¨ä¾‹ã‚’å®Ÿè¡Œ"""
    print("\n" + "ğŸŒŸ"*35)
    print("LangChain ãƒã‚§ãƒ¼ãƒ³ å®Ÿç”¨ä¾‹é›†")
    print("ğŸŒŸ"*35)
    
    use_cases = [
        ("ãƒ–ãƒ­ã‚°è¨˜äº‹è‡ªå‹•ç”Ÿæˆ", blog_generation_pipeline),
        ("ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆãƒœãƒƒãƒˆ", customer_support_bot),
        ("ã‚³ãƒ³ãƒ†ãƒ³ãƒ„å“è³ªãƒã‚§ãƒƒã‚«ãƒ¼", content_quality_checker),
        ("ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ", data_analysis_report),
    ]
    
    print("\nå®Ÿè¡Œã™ã‚‹ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„:")
    for i, (name, _) in enumerate(use_cases, 1):
        print(f"{i}. {name}")
    print("0. å…¨ã¦å®Ÿè¡Œ")
    
    try:
        choice = input("\nç•ªå·ã‚’å…¥åŠ› (0-4): ").strip()
        
        if choice == "0":
            for name, func in use_cases:
                await func()
        elif choice.isdigit() and 1 <= int(choice) <= len(use_cases):
            _, func = use_cases[int(choice) - 1]
            await func()
        else:
            print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")
            return
            
    except KeyboardInterrupt:
        print("\n\nâš ï¸  å®Ÿè¡ŒãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "ğŸ‰"*35)
    print("å®Ÿç”¨ä¾‹ã®å®Ÿè¡Œå®Œäº†ï¼")
    print("ğŸ‰"*35 + "\n")

if __name__ == "__main__":
    asyncio.run(main())
